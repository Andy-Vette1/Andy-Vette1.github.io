# Week 01 笔记：机器学习与数学基础回顾

本笔记基于 FIT3181/5215 课程 Week 01 内容整理。

---

## 一、线性代数基础 (Linear Algebra Revision)

### 0. 为什么深度学习需要向量？(Why Vectors?)
**核心逻辑**：计算机无法直接“看懂”图片或“读懂”文字，它只能处理数字。
* **特征表示**：向量是将现实世界的非结构化数据（如图像、文本、音频）转化为计算机可计算的**数值列表**的工具。
    * *例子*：一张图片可以看作是一个巨大的像素值向量；一个单词可以映射为一个词向量（Word Embedding）。
* **计算基础**：一旦转化成向量（如 $\mathbf{x} \in \mathbb{R}^n$），我们就可以利用数学工具（如距离公式、相似度）来衡量事物之间的差异，或者通过矩阵运算提取更高阶的特征。

### 1. 向量（Vector）
一个 $n$ 维向量写作：$$\mathbf{x} = (x_1, x_2, \dots, x_n)^\top \in \mathbb{R}^n$$

**常见操作**：
* **转置** (Transpose)：$\mathbf{x}^\top$ 把列向量变成行向量。
* **向量加法**：$(\mathbf{x} + \mathbf{y})_i = x_i + y_i$。
* **内积** (Inner product)：$\mathbf{x}^\top \mathbf{y} = \sum_{i=1}^n x_i y_i$

### 2. 范数
$p$-范数定义为：
$$\|\mathbf{x}\|_p = \left( \sum_\{i=1}^n |x_i|^p \right)^{1/p}, \quad p>0$$

**范数** (Norms)：衡量向量的“长度”或“大小”。
  * L0 范数：$\|\mathbf{x}\|_0$, 非零元素的个数，用于衡量**稀疏性** (Sparsity)。
  * L1 范数：$\|\mathbf{x}\|_1 = \sum_i |x_i|$, 绝对值之和。
  * L2 范数：$\|\mathbf{x}\|_2 = \sqrt{\sum_i x_i^2}$, 欧几里得长度（直线距离）。

### 3. 距离与相似度 (重点概念)
* **欧氏距离** (Euclidean distance)：$$d = \|\mathbf{x}-\mathbf{y}\|_2 = \sqrt{\sum_\{i=1}^{n}(x_i - y_i)^2}$$ 衡量**绝对数值差距**。
* **向量长度**（Length of a vector）：$$\text{length}(\mathbf{x}) = \|\mathbf{x}\| = \sqrt{x_1^2 + x_2^2 + \dots + x_n^2}$$ $$\|\mathbf{x}\|_2 = \sqrt{x_1^2 + x_2^2 + \dots + x_n^2}$$
* **余弦相似度** (Cosine similarity)：$$\cos(\theta) = \cos(\mathbf{x}, \mathbf{y}) = \frac{\mathbf{x}^\top \mathbf{y}}{\|\mathbf{x}\| \|\mathbf{y}\|}$$ 衡量**方向的一致性**，范围 $[-1, 1]$。
* **余弦距离**：$d_{\text{cos}}(\mathbf{x}, \mathbf{y}) = 1 - \cos(\mathbf{x}, \mathbf{y})$。


> **💡 通俗理解与区别**
> * **欧氏距离（物理距离）**：
>     * **含义**：两点之间拉直线的绝对长度。它对**数值量级**非常敏感。
>     * **例子**：淘宝购物，A 花 100 元买 1 件衣服，B 花 1000 元买 10 件衣服。用欧氏距离看，(100) 和 (1000) 距离很远，因为 B 的消费力远大于 A。
> * **余弦相似度（方向偏好）**：
>     * **含义**：看两个向量是否指向同一个方向，不管它们有多长。它衡量的是**结构或兴趣的重合度**。
>     * **例子**：还是 A 和 B，虽然花的钱不同，但买的都是“衣服”这一类。用余弦相似度看，他们的方向一致（夹角为 0），相似度极高。
>     * **应用**：在文本分类中，我们更关心单词的含义方向（如 King 和 Queen 很像），而不是出现的频率次数。

### 4. 矩阵与张量 (Matrix & Tensor)
* **矩阵** (Matrix)：二维数组，例如 $A \in \mathbb{R}^{m \times n}$。
    * 矩阵乘法：若 $A \in \mathbb{R}^{m \times n}, B \in \mathbb{R}^{n \times p}$，则 $C = AB \in \mathbb{R}^{m \times p}$。
    * 计算公式：$c_{ij} = \sum_{k=1}^n a_{ik} b_{kj}$。
* **张量** (Tensor)：多维数组的统称。
    * 0D: 标量 (Scalar)
    * 1D: 向量 (Vector)
    * 2D: 矩阵 (Matrix)
    * 3D+: 张量 (Tensor 如 RGB 图像 $H \times W \times 3$)

---

## 二、核心术语表 (Key Terminology)
> 这里汇总了深度学习中常见但容易混淆的专业名词。

### 1. 标签与编码
* **Ground-truth label (真实标签)**
    * **定义**：数据的“标准答案”或“正确标注”。在监督学习中，用 $y$ 表示。
    * *例子*：训练数据是一张猫的照片，人工给它的标记“猫”就是 Ground-truth。
* **One-hot Encoding (独热编码)**
    * **定义**：将离散的类别标签转化为向量的一种方式。向量中只有一个位置是 1，其余全为 0。
    * *例子*：如果有 3 个类别 [猫, 狗, 鸟]，猫 (Class 1) 表示为 `[1, 0, 0]`，狗 (Class 2) 表示为 `[0, 1, 0]`。
    * *作用*：让离散类别可以参与数学运算，并表示 100% 的确定性。

### 2. 模型输出相关
* **Logits (逻辑值/原始分数)**
    * **定义**：模型在最后一层输出的**原始数值**（Raw Scores），通常范围是 $(-\infty, +\infty)$。
    * *注意*：Logits 不是概率，它还未经过归一化处理。Logits 越大，代表模型认为属于该类的可能性越大。
* **Softmax activation function (Softmax 激活函数)**
    * **定义**：将 Logits 压缩到 $(0, 1)$ 之间，并确保所有类别的输出之和为 1，从而转化为**概率分布**。
    * **公式**：$p_m = \frac{e^{h_m}}{\sum e^{h_i}}$。
    * *作用*：让神经网络的输出可以被解释为“属于某一类的概率”。

---

## 三、信息论基础 (Information Theory)

> **为什么要学这些？**
> 这些概念是训练神经网络的“尺子”。我们需要一个量化的标准来告诉模型：你的预测离真实答案还有多远？

### 1. 熵 (Entropy)
对于离散分布 $p = (p_1, \dots, p_d)$，香农熵定义为：
$$H(p) = -\sum_{i=1}^d p_i \log p_i$$
* **直观理解**：衡量系统的**混乱程度**或**不确定性**。熵越大，分布越均匀，越难猜到结果（比如红黄蓝绿球各 25%）；熵越小，越确定（比如全是红球）。

### 2. KL 散度 (Kullback-Leibler Divergence)
衡量两个分布 $p$ (真实分布) 和 $q$ (预测分布) 之间的**差异**（或距离）：
$$\mathrm{KL}(p \| q) = \sum_{i=1}^d p_i \log \frac{p_i}{q_i}$$
* **性质**：$\mathrm{KL}(p \| q) \ge 0$，当且仅当 $p=q$ 时为 0。
* **直观理解**：如果 $P$ 是真实答案（这图是猫），$Q$ 是模型的猜测（60%是猫）。KL 散度越小，说明模型猜测得越准。

### 3. 交叉熵 (Cross-Entropy)
深度学习中最常用的分类损失函数：
$$\mathrm{CE}(p, q) = -\sum_{i=1}^d p_i \log q_i$$
* **关系公式**：$\mathrm{CE}(p, q) = \mathrm{KL}(p \| q) + H(p)$。
* **为什么用它**：在训练中，真实标签 $P$ 通常是固定的（即 $H(p)$ 是常数）。因此，**最小化交叉熵** 等价于 **最小化 KL 散度**（让预测分布逼近真实分布）。计算交叉熵比计算 KL 散度更简单。

> **补充：One-hot 编码**
> 为了计算交叉熵，我们需要将类别标签（如 "Cat" 或 label=1）转化为概率分布向量。
> * 例如：3 分类问题中，Label=1 转化为 One-hot 向量 `[1, 0, 0]`。
> * 这样不仅表示了类别，还表示了 $100\%$ 的确定性概率，便于和 Softmax 输出的概率进行计算。

---

## 四、机器学习回顾 (Machine Learning Revisited)

### 0. 机器学习流派 (The Five Tribes) [补充]
虽然深度学习主要属于**联结主义**，但了解历史有助于建立宏观视野：
1.  **符号主义** (Symbolists)：逻辑与哲学，通过**逆向演绎**学习（如决策树、逻辑推理）。
2.  **联结主义** (Connectionists)：神经科学，通过**反向传播**优化大脑神经网络（如深度学习）。
3.  **进化主义** (Evolutionary)：进化生物学，通过**遗传算法**进行结构发现。
4.  **贝叶斯派** (Bayesians)：统计学，基于**贝叶斯定理**处理不确定性。
5.  **类推主义** (Analogizers)：心理学，通过**相似性**学习（如 SVM, KNN）。

### 1. 机器学习三要素
1.  **数据** (Data)：输入 $\mathbf{x} \in \mathbb{R}^d$，标签 $y$。
2.  **模型** (Model)：函数 $f: \mathcal{X} \to \mathcal{Y}$。
3.  **评估** (Assessment)：损失函数与准确率。

### 2. 机器学习两大核心任务：分类 vs 回归
这是机器学习中最常见的两种形式。

| 维度         | **分类 (Classification)**                                     | **回归 (Regression)**                                   |
| :----------- | :------------------------------------------------------------ | :------------------------------------------------------ |
| **标签类型** | **离散类别** (Discrete) <br> (如：猫/狗，垃圾邮件/正常邮件)   | **连续数值** (Continuous) <br> (如：房价预测，气温预测) |
| **输出形式** | 通常是**概率分布** (Probability Distribution)                 | 一个**实数值** (Real Value)                             |
| **损失函数** | **交叉熵 (Cross-Entropy Loss)** <br> 衡量“概率分布”之间的差异 | **均方误差 (MSE / L2 Loss)** <br> 衡量“数值”之间的距离  |
| **决策方式** | 取概率最大的类别 ($\arg\max$)                                 | 直接输出函数值 ($f(x)$)                                 |

### 3. 监督学习和无监督学习 (Supervised Learning VS. Unsupervised Learning)

#### 监督学习 (Supervised Learning)

**定义**：
监督学习的核心是**从数据中学习一个函数**，用来建立**输入 (Inputs)** 与 **输出 (Outputs)** 之间的映射关系。最关键的特征是训练数据中包含了**标签** (Labels)，即我们已经知道正确的答案。

**数学表达**：
* **数据集**：$D = \{(x_1, y_1), ..., (x_N, y_N)\}$
    * 这里每一个样本不仅有特征 $x$，还有对应的标签 $y$。
* **目标函数**：$f: X \rightarrow Y$
    * 目的是找到一个函数 $f$，使得 $f(x) \approx y$。

**输入与输出的类型**：
* **输入特征**：$x \in \mathbb{R}^d$（$d$ 维特征向量）。
* **输出标签** $y$ 决定了任务的类型：
    1.  **分类** (Classification)：当 $y$ 是**离散**的标签时。
        * 例如：$y \in \{1, 2, ..., M\}$。
        * 场景：垃圾邮件检测（是/否）、图像识别（猫/狗）。
    2.  **回归** (Regression)：当 $y$ 是**连续**的数值时。
        * 例如：$y \in \mathbb{R}$。
        * 场景：预测房价、预测明天的气温。

---

#### 无监督学习 (Unsupervised Learning)

**定义**：
与监督学习不同，无监督学习的数据**没有标签**。模型只能通过分析数据本身的特征，去寻找数据内部的**结构**、**模式**或**分布**。

**数学表达**：
* **数据集**：$D = \{x_1, x_2, ..., x_N\}$
    * 注意：这里只有输入 $x$，没有对应的标签 $y$。

**常见任务**：
1.  **聚类** (Clustering)：将相似的数据点归为一组（例如：用户分群）。
2.  **降维** (Dimensionality Reduction)：在保留主要信息的前提下简化数据（例如：PCA）。
3.  **密度估计** (Density Estimation)：估计数据的分布情况。
4.  **异常检测** (Anomaly Detection)：找出与大多数数据不同的异常点。

---

#### 深度学习属于哪一类？

**结论：深度学习 (Deep Learning) 既可以是监督学习，也可以是无监督学习，但目前最主流的应用大多属于监督学习。**

1.  **作为监督学习** (Discriminative)：
    * 在课程中，深度学习常被放在 **"Discriminative Machine Learning" (判别式机器学习)** 的背景下讨论。
    * **典型应用**：卷积神经网络 (CNN) 用于图像分类（ImageNet）、人脸识别、物体检测等。这些任务都需要大量的带标签数据进行训练（输入图片 -> 输出类别），因此属于典型的**监督学习**。

2.  **作为无监督学习** (Generative)：
    * 深度学习也可以用于无监督任务。
    * **典型应用**：DeepDream、DALL-E 或 Google Imagen 这种生成式模型。虽然训练过程复杂，但本质上很多生成模型（如 GANs, VAEs）利用了无监督或自监督的学习方式来学习数据的分布，从而生成新的图像。

**总结**：
深度学习是一种**方法（Method）**——即使用多层神经网络来解决问题。
* 如果你给它带标签的数据（如：图片+分类名），它就是**监督学习**（这是课程目前的重点）。
* 如果你只给它数据让它自己找规律（如：生成相似图片），它就是**无监督学习**。

---

## 五、深度学习和判别式学习 (DL & Discriminative ML)

### 1. 判别式学习 (Discriminative ML)
* **概念**：判别式模型不关心数据是怎么生成的，只关心**决策边界** (Decision Boundary)。它学习的是条件概率 $P(Y|X)$，即给定输入 $X$，将其归类为 $Y$ 的概率。
* **流程**：
    1.  **Logits**: 模型输出的原始分数 $h(\mathbf{x}) = (h_1, \dots, h_M)$。
    2.  **Softmax**: 将 logits 转化为概率分布：
        $$p_m(\mathbf{x}) = \frac{\exp(h_m(\mathbf{x}))}{\sum_{i=1}^M \exp(h_i(\mathbf{x}))}$$
    3.  **预测**: $\hat{y} = \arg\max_m p_m(\mathbf{x})$。

虽然名字里带“回归”，但它实际上是一个**线性分类模型**。它是深度学习中最简单的基础单元（单层神经网络）。

#### 结构与流程
逻辑回归的处理流程完美体现了判别式学习的过程：
1.  **线性变换**：输入 $x$ 乘以权重 $W$ 加上偏置 $b$，得到 Logits。
    $$h(x) = xW + b$$
2.  **激活** (Activation)：使用 **Softmax** (多分类) 将 Logits 转化为概率。
    $$p(x) = \text{softmax}(h(x))$$
3.  **预测**：选择概率最大的类别作为预测结果 $\hat{y}$。

> **补充：逻辑回归 vs 前向传播**
> * **逻辑回归**是一个具体的**模型** (Model)。
> * **前向传播 (Feed-forward)** 是数据流动的**过程** (Process)。逻辑回归的计算过程（输入 -> 加权求和 -> 激活 -> 输出）就是一次简单的前向传播。

#### 训练与优化
* **训练目标**：最小化所有样本的平均交叉熵损失。
* **优化算法** (Optimizers) [补充]：
    虽然笔记里只说了“最小化”，但实际中我们需要算法来自动调整参数 $W$ 和 $b$。常用的优化器包括：
    * **SGD** (随机梯度下降)
    * **Adam** (目前最常用的自适应算法)
    * **RMSprop**

---

### 2. 分类任务 (Classification)

#### 基本流程
在分类任务中，模型的目标是将输入 $x$ 映射到一个离散的标签 $y \in \{1, ..., M\}$。
* **模型输出** (Logits)：模型首先输出一组原始分数 $h(x)$，这些分数称为 **Logits**（判别值）。
* **预测** (Prediction)：选择 Logits 中数值最大的那个类别作为预测结果 $\hat{y}$。
* **损失** (Loss)：计算预测结果与真实标签之间的差异。

#### 核心组件：Softmax
Logits 是实数值 $(-\infty, +\infty)$，为了进行概率解释，我们需要 **Softmax**。
* **作用**：将 Logits 转化为**概率分布** $p(x)$。
* **性质**：转化后的概率都在 $[0, 1]$ 之间，且总和为 1。Softmax 保持了原始分数的大小顺序。

#### 核心组件：交叉熵损失 (Cross-Entropy Loss)
这是分类任务最常用的损失函数。
* **One-hot 编码**：将真实标签 $y$ 转化为向量（例如类别 1 变为 $[1, 0, 0]$）。
* **公式**：
  $$l(y, \hat{y}) = \text{CE}(1_y, p) = -\log p_y$$
  即：我们只关心**正确类别**对应的预测概率 $p_y$。如果模型对正确类别的预测概率越高（越接近 1），损失就越小（越接近 0）。

---

### 3. 回归任务 (Regression)

这是判别式学习的另一种任务类型。
* **目标**：输入 $x$，预测一个**连续的实数值** $y \in \mathbb{R}$。
* **预测**：不需要 Softmax，直接输出模型的计算结果 $\hat{y} = h(x)$。
* **损失函数**：
    * **L2** Loss (均方误差)：$l = \frac{1}{2}(y - \hat{y})^2$。
    * **L1** Loss (绝对误差)：$l = |y - \hat{y}|$。

---

#### 逻辑回归 (Logistic Regression)

**注意**：尽管名字叫“回归”，逻辑回归实际上是一个用于**分类**的线性模型。它可以看作是神经网络的最基础形式（单层网络）。

##### 1. 计算过程 (Computational Process)
逻辑回归完整地展示了分类任务的三个步骤：
1.  **线性变换**：$h(x) = xW + b$ （得到 Logits）。
2.  **激活**：$p(x) = \text{softmax}(h(x))$ （得到概率）。
3.  **预测**：$\hat{y} = \arg\max p(x)$ （输出类别）。

##### 2. 训练管道 (Pipeline)
1.  **数据输入**：将数据分成一个个 **Mini-batch**（小批量），例如 64 个样本一组（1 epoch）。
2.  **前向传播**：计算预测概率。
3.  **计算损失**：使用交叉熵计算当前 Batch 的平均损失。
4.  **参数更新**：使用优化器（如 **SGD**, **Adam**, **RMSprop**）来调整参数 $W$ 和 $b$。
5.  **测试**：在测试集上评估模型的准确率。